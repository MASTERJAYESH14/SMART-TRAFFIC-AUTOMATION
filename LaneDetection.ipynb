{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/MaybeShewill-CV/lanenet-lane-detection.git\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd E:\\Codes\\smart_traffic\\lanenet-lane-detection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Disable eager execution to use TensorFlow 1.x syntax\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "config = tf.compat.v1.ConfigProto(device_count={'GPU': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 4351734664601887186\n",
      "xla_global_id: -1\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path):\n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.resize(image, (512, 256))\n",
    "\n",
    "    # Convert the image from BGR to RGB (OpenCV loads images in BGR format)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Normalize pixel values to the range expected by the model (e.g., 0 to 1)\n",
    "    image = image / 255.0\n",
    "\n",
    "    # Expand dimensions to match the expected batch size (1, height, width, channels)\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def process_output(binary_segmentation, instance_segmentation, original_image):\n",
    "\n",
    "    # Resize binary_segmentation to match original image size\n",
    "    binary_segmentation_resized = cv2.resize(binary_segmentation, \n",
    "                                             (original_image.shape[1], original_image.shape[0]),\n",
    "                                             interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "    # Threshold binary segmentation to create a binary mask\n",
    "    binary_mask = (binary_segmentation_resized > 0.5).astype(np.uint8) * 255\n",
    "\n",
    "    # Overlay binary mask on the original image\n",
    "    overlay = original_image.copy()\n",
    "    overlay[binary_mask == 255] = [0, 255, 0]  # Green color for lanes\n",
    "\n",
    "    # Instance segmentation (optional): further refine lane detection per instance\n",
    "    instance_segmentation_resized = cv2.resize(instance_segmentation, \n",
    "                                               (original_image.shape[1], original_image.shape[0]),\n",
    "                                               interpolation=cv2.INTER_NEAREST)\n",
    "    \n",
    "    # Apply clustering or contouring (depends on model output) for unique lane representation\n",
    "    # Here we extract contours for each unique lane if possible\n",
    "    num_lanes = np.unique(instance_segmentation_resized)\n",
    "    for lane_id in num_lanes:\n",
    "        if lane_id == 0:  # skip background\n",
    "            continue\n",
    "        lane_mask = (instance_segmentation_resized == lane_id).astype(np.uint8)\n",
    "        \n",
    "        # Find contours to draw lane line\n",
    "        contours, _ = cv2.findContours(lane_mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        cv2.drawContours(overlay, contours, -1, (0, 0, 255), 2)  # Red color for unique lanes\n",
    "\n",
    "    # Combine overlay with original image for visualization\n",
    "    output_image = cv2.addWeighted(original_image, 0.7, overlay, 0.3, 0)\n",
    "\n",
    "    return output_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The saved meta_graph is possibly from an older release:\n",
      "'metric_variables' collection should be of type 'byte_list', but instead is of type 'node_list'.\n",
      "INFO:tensorflow:Restoring parameters from E:\\Codes\\smart_traffic\\lanenet-lane-detection\\checkpoint\\tusimple_lanenet.ckpt\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Restoring from checkpoint failed. This is most likely due to a mismatch between the current graph and the graph from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:\n\nGraph execution error:\n\nDetected at node 'LaneNet/bisenetv2_frontend/detail_branch/stage_1/conv_block_1_repeat_1/3x3_conv/conv/W/Initializer/truncated_normal/TruncatedNormal' defined at (most recent call last):\nNode: 'LaneNet/bisenetv2_frontend/detail_branch/stage_1/conv_block_1_repeat_1/3x3_conv/conv/W/Initializer/truncated_normal/TruncatedNormal'\nCannot assign a device for operation LaneNet/bisenetv2_frontend/detail_branch/stage_1/conv_block_1_repeat_1/3x3_conv/conv/W/Initializer/truncated_normal/TruncatedNormal: {{node LaneNet/bisenetv2_frontend/detail_branch/stage_1/conv_block_1_repeat_1/3x3_conv/conv/W/Initializer/truncated_normal/TruncatedNormal}} was explicitly assigned to /device:GPU:0 but available devices are [ /job:localhost/replica:0/task:0/device:CPU:0 ]. Make sure the device specification refers to a valid device. The requested device appears to be a GPU, but CUDA is not enabled.\n\t [[LaneNet/bisenetv2_frontend/detail_branch/stage_1/conv_block_1_repeat_1/3x3_conv/conv/W/Initializer/truncated_normal/TruncatedNormal]]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\tyagi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\client\\session.py:1401\u001b[0m, in \u001b[0;36mBaseSession._do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1400\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1401\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1402\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mOpError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\tyagi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\client\\session.py:1383\u001b[0m, in \u001b[0;36mBaseSession._do_run.<locals>._run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1381\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_fn\u001b[39m(feed_dict, fetch_list, target_list, options, run_metadata):\n\u001b[0;32m   1382\u001b[0m   \u001b[38;5;66;03m# Ensure any changes to the graph are reflected in the runtime.\u001b[39;00m\n\u001b[1;32m-> 1383\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_extend_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1384\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m   1385\u001b[0m                                   target_list, run_metadata)\n",
      "File \u001b[1;32mc:\\Users\\tyagi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\client\\session.py:1424\u001b[0m, in \u001b[0;36mBaseSession._extend_graph\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1423\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph\u001b[38;5;241m.\u001b[39m_session_run_lock():  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m-> 1424\u001b[0m   \u001b[43mtf_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mExtendSession\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_session\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Cannot assign a device for operation LaneNet/bisenetv2_frontend/detail_branch/stage_1/conv_block_1_repeat_1/3x3_conv/conv/W/Initializer/truncated_normal/TruncatedNormal: {{node LaneNet/bisenetv2_frontend/detail_branch/stage_1/conv_block_1_repeat_1/3x3_conv/conv/W/Initializer/truncated_normal/TruncatedNormal}} was explicitly assigned to /device:GPU:0 but available devices are [ /job:localhost/replica:0/task:0/device:CPU:0 ]. Make sure the device specification refers to a valid device. The requested device appears to be a GPU, but CUDA is not enabled.\n\t [[LaneNet/bisenetv2_frontend/detail_branch/stage_1/conv_block_1_repeat_1/3x3_conv/conv/W/Initializer/truncated_normal/TruncatedNormal]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\tyagi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\training\\saver.py:1422\u001b[0m, in \u001b[0;36mSaver.restore\u001b[1;34m(self, sess, save_path)\u001b[0m\n\u001b[0;32m   1421\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1422\u001b[0m     \u001b[43msess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msaver_def\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrestore_op_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1423\u001b[0m \u001b[43m             \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msaver_def\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilename_tensor_name\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_path\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1424\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mNotFoundError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m   1425\u001b[0m   \u001b[38;5;66;03m# There are three common conditions that might cause this error:\u001b[39;00m\n\u001b[0;32m   1426\u001b[0m   \u001b[38;5;66;03m# 0. The file is missing. We ignore here, as this is checked above.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1430\u001b[0m   \u001b[38;5;66;03m# 1. The checkpoint would not be loaded successfully as is. Try to parse\u001b[39;00m\n\u001b[0;32m   1431\u001b[0m   \u001b[38;5;66;03m# it as an object-based checkpoint.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\tyagi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\client\\session.py:971\u001b[0m, in \u001b[0;36mBaseSession.run\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    970\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 971\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfetches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions_ptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mrun_metadata_ptr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    973\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m run_metadata:\n",
      "File \u001b[1;32mc:\\Users\\tyagi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\client\\session.py:1214\u001b[0m, in \u001b[0;36mBaseSession._run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m final_fetches \u001b[38;5;129;01mor\u001b[39;00m final_targets \u001b[38;5;129;01mor\u001b[39;00m (handle \u001b[38;5;129;01mand\u001b[39;00m feed_dict_tensor):\n\u001b[1;32m-> 1214\u001b[0m   results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal_targets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal_fetches\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1215\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mfeed_dict_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1216\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\tyagi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\client\\session.py:1394\u001b[0m, in \u001b[0;36mBaseSession._do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1393\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m handle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1394\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_run_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeeds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfetches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1395\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1396\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\tyagi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\client\\session.py:1420\u001b[0m, in \u001b[0;36mBaseSession._do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1416\u001b[0m   message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mA possible workaround: Try disabling Grappler optimizer\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   1417\u001b[0m               \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mby modifying the config for creating the session eg.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   1418\u001b[0m               \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124msession_config.graph_options.rewrite_options.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   1419\u001b[0m               \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisable_meta_optimizer = True\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m-> 1420\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(e)(node_def, op, message)\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'LaneNet/bisenetv2_frontend/detail_branch/stage_1/conv_block_1_repeat_1/3x3_conv/conv/W/Initializer/truncated_normal/TruncatedNormal' defined at (most recent call last):\nNode: 'LaneNet/bisenetv2_frontend/detail_branch/stage_1/conv_block_1_repeat_1/3x3_conv/conv/W/Initializer/truncated_normal/TruncatedNormal'\nCannot assign a device for operation LaneNet/bisenetv2_frontend/detail_branch/stage_1/conv_block_1_repeat_1/3x3_conv/conv/W/Initializer/truncated_normal/TruncatedNormal: {{node LaneNet/bisenetv2_frontend/detail_branch/stage_1/conv_block_1_repeat_1/3x3_conv/conv/W/Initializer/truncated_normal/TruncatedNormal}} was explicitly assigned to /device:GPU:0 but available devices are [ /job:localhost/replica:0/task:0/device:CPU:0 ]. Make sure the device specification refers to a valid device. The requested device appears to be a GPU, but CUDA is not enabled.\n\t [[LaneNet/bisenetv2_frontend/detail_branch/stage_1/conv_block_1_repeat_1/3x3_conv/conv/W/Initializer/truncated_normal/TruncatedNormal]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m saver \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mcompat\u001b[38;5;241m.\u001b[39mv1\u001b[38;5;241m.\u001b[39mtrain\u001b[38;5;241m.\u001b[39mimport_meta_graph(ckpt_path \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.meta\u001b[39m\u001b[38;5;124m'\u001b[39m, clear_devices\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Restore the weights from the checkpoint\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m \u001b[43msaver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrestore\u001b[49m\u001b[43m(\u001b[49m\u001b[43msess\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Get the input and output tensors by their names from the graph\u001b[39;00m\n\u001b[0;32m     14\u001b[0m graph \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mcompat\u001b[38;5;241m.\u001b[39mv1\u001b[38;5;241m.\u001b[39mget_default_graph()\n",
      "File \u001b[1;32mc:\\Users\\tyagi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\training\\saver.py:1458\u001b[0m, in \u001b[0;36mSaver.restore\u001b[1;34m(self, sess, save_path)\u001b[0m\n\u001b[0;32m   1454\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_object_restore_saver\u001b[38;5;241m.\u001b[39mrestore(sess\u001b[38;5;241m=\u001b[39msess, save_path\u001b[38;5;241m=\u001b[39msave_path)\n\u001b[0;32m   1455\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mInvalidArgumentError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m   1456\u001b[0m   \u001b[38;5;66;03m# There is a mismatch between the graph and the checkpoint being loaded.\u001b[39;00m\n\u001b[0;32m   1457\u001b[0m   \u001b[38;5;66;03m# We add a more reasonable error message here to help users (b/110263146)\u001b[39;00m\n\u001b[1;32m-> 1458\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m _wrap_restore_error_with_msg(\n\u001b[0;32m   1459\u001b[0m       err, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma mismatch between the current graph and the graph\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1460\u001b[0m metrics\u001b[38;5;241m.\u001b[39mAddCheckpointReadDuration(\n\u001b[0;32m   1461\u001b[0m     api_label\u001b[38;5;241m=\u001b[39m_SAVER_LABEL,\n\u001b[0;32m   1462\u001b[0m     microseconds\u001b[38;5;241m=\u001b[39m_get_duration_microseconds(start_time, time\u001b[38;5;241m.\u001b[39mtime()))\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Restoring from checkpoint failed. This is most likely due to a mismatch between the current graph and the graph from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:\n\nGraph execution error:\n\nDetected at node 'LaneNet/bisenetv2_frontend/detail_branch/stage_1/conv_block_1_repeat_1/3x3_conv/conv/W/Initializer/truncated_normal/TruncatedNormal' defined at (most recent call last):\nNode: 'LaneNet/bisenetv2_frontend/detail_branch/stage_1/conv_block_1_repeat_1/3x3_conv/conv/W/Initializer/truncated_normal/TruncatedNormal'\nCannot assign a device for operation LaneNet/bisenetv2_frontend/detail_branch/stage_1/conv_block_1_repeat_1/3x3_conv/conv/W/Initializer/truncated_normal/TruncatedNormal: {{node LaneNet/bisenetv2_frontend/detail_branch/stage_1/conv_block_1_repeat_1/3x3_conv/conv/W/Initializer/truncated_normal/TruncatedNormal}} was explicitly assigned to /device:GPU:0 but available devices are [ /job:localhost/replica:0/task:0/device:CPU:0 ]. Make sure the device specification refers to a valid device. The requested device appears to be a GPU, but CUDA is not enabled.\n\t [[LaneNet/bisenetv2_frontend/detail_branch/stage_1/conv_block_1_repeat_1/3x3_conv/conv/W/Initializer/truncated_normal/TruncatedNormal]]"
     ]
    }
   ],
   "source": [
    "image_path = \"C:\\\\Users\\\\tyagi\\\\OneDrive\\\\Desktop\\\\Images Output\\\\drone\\\\seq3-drone_0000001.jpg\"\n",
    "with tf.device('/cpu:0'):\n",
    "    with tf.compat.v1.Session(config=config) as sess:\n",
    "        # Define the checkpoint path\n",
    "        ckpt_path = \"E:\\\\Codes\\\\smart_traffic\\\\lanenet-lane-detection\\\\checkpoint\\\\tusimple_lanenet.ckpt\"\n",
    "\n",
    "        # Load the model graph\n",
    "        saver = tf.compat.v1.train.import_meta_graph(ckpt_path + '.meta', clear_devices=True)\n",
    "\n",
    "        # Restore the weights from the checkpoint\n",
    "        saver.restore(sess, ckpt_path)\n",
    "\n",
    "        # Get the input and output tensors by their names from the graph\n",
    "        graph = tf.compat.v1.get_default_graph()\n",
    "        input_tensor = graph.get_tensor_by_name('input_tensor_name:0')  # Replace with the actual input tensor name\n",
    "        output_tensor = graph.get_tensor_by_name('output_tensor_name:0')  # Replace with the actual output tensor name\n",
    "\n",
    "        # Preprocess the input image as required by the model\n",
    "        input_image = preprocess_image(image_path)  # Implement this function as needed\n",
    "\n",
    "        # Run inference\n",
    "        output = sess.run(output_tensor, feed_dict={input_tensor: input_image})\n",
    "\n",
    "        # Process and visualize the output\n",
    "        process_output(output)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
